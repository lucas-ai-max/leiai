import openai
from config import settings
import fitz  # PyMuPDF
from tenacity import retry, stop_after_attempt, wait_exponential

class OpenAIClient:
    def __init__(self):
        if not settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY n√£o configurada no .env")
        
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model_name = settings.MODEL_OPENAI
        print(f"‚úÖ Cliente OpenAI inicializado: {self.model_name}")

    def analyze_document(self, file_path: str, prompt_text: str) -> str:
        """
        Analisa documento usando OpenAI GPT-4o.
        Estrat√©gia: Extrair texto do PDF e enviar como mensagem.
        """
        
        # 1. Extrair texto do PDF
        try:
            doc = fitz.open(file_path)
            text_content = ""
            for page in doc:
                text_content += page.get_text()
            doc.close()
            
            # Estimativa b√°sica de tokens (1 token ~= 4 chars)
            # GPT-4o tem 128k context, mas output √© limitado (4k/16k dependendo do modelo)
            # Se for muito grande, avisar no log
            token_est = len(text_content) // 4
            print(f"   üìÑ Texto extra√≠do: {token_est} tokens (aprox.)")
            
            # DEBUG CR√çTICO: Ver o que est√° sendo lido
            print("\n   üîç --- IN√çCIO DO TEXTO EXTRA√çDO (DEBUG) ---")
            print(text_content[:600]) # Primeiros 600 caracteres
            print("   üîç --- FIM DO DEBUG ---\n")

            # Valida√ß√£o anti-alucina√ß√£o: Se n√£o h√° texto suficiente, √© prov√°vel que seja imagem/scan.
            if len(text_content.strip()) < 50:
                print("   ‚ö†Ô∏è AVISO: Texto extra√≠do insuficiente (< 50 chars). Documento pode ser imagem.")
                raise ValueError("DOC_VAZIO: Documento escaneado ou imagem sem camada de texto (OCR necess√°rio).")
            
        except Exception as e:
            raise ValueError(f"Erro ao ler PDF: {e}")

        # 2. Enviar para OpenAI
        json_resp = self._call_openai(text_content, prompt_text)
        return json_resp, text_content

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def _call_openai(self, text: str, prompt: str) -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente jur√≠dico especializado em an√°lise de documentos. Responda estritamente em JSON."},
                    {"role": "user", "content": f"{prompt}\n\nDOCUMENTO:\n{text}"}
                ],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            content = response.choices[0].message.content
            if not content:
                raise ValueError("Resposta vazia da OpenAI")
            
            return content
            
        except Exception as e:
            # Tratamento b√°sico de erros
            raise ValueError(f"Erro na OpenAI API: {e}")
