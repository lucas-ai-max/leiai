#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import streamlit as st
from pathlib import Path
import glob
import os
import sys
from datetime import datetime
import pandas as pd
import json
import logging
import warnings
from threading import Lock

# Configurar encoding UTF-8 para Windows
# NOTA: NÃ£o reconfigurar sys.stdout/stderr para evitar "I/O operation on closed file"
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    # NÃ£o reconfigurar sys.stdout/stderr - pode causar problemas com Streamlit

# Configurar logging para filtrar erros de WebSocket do Tornado
logging.getLogger("tornado.access").setLevel(logging.ERROR)
logging.getLogger("tornado.application").setLevel(logging.ERROR)
logging.getLogger("tornado.general").setLevel(logging.ERROR)
logging.getLogger("tornado.websocket").setLevel(logging.ERROR)

# Suprimir warnings de WebSocket fechado
warnings.filterwarnings("ignore", category=RuntimeWarning, message=".*WebSocket.*")
warnings.filterwarnings("ignore", message=".*Task exception was never retrieved.*")

# #region agent log
def debug_log(location, message, data, hypothesis_id="A", session_id="debug-session", run_id="run1"):
    """Debug logging helper - garante que diretÃ³rio existe"""
    log_path = r'c:\Users\TRIA 2026\Downloads\ProcessIA\.cursor\debug.log'
    try:
        os.makedirs(os.path.dirname(log_path), exist_ok=True)
        log_entry = {
            "sessionId": session_id,
            "runId": run_id,
            "hypothesisId": hypothesis_id,
            "location": location,
            "message": message,
            "data": data,
            "timestamp": int(__import__('time').time()*1000)
        }
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    except Exception as e:
        # Fallback: tentar escrever no diretÃ³rio atual
        try:
            with open("debug.log", "a", encoding="utf-8") as f:
                f.write(json.dumps({"error": str(e), "error_type": type(e).__name__, "original": {"location": location, "message": message}}, ensure_ascii=False) + "\n")
        except:
            pass
# Teste inicial
debug_log("app.py:62", "DEBUG LOG INICIALIZADO", {"test": True}, "TEST")
# #endregion

# Importar processor normalmente (sem reload forÃ§ado para evitar conflitos)
try:
    # #region agent log
    debug_log("app.py:67", "TENTANDO IMPORTAR processor", {"path": str(Path(__file__).parent)}, "A")
    # #endregion
    from processor import DocumentProcessor
    # #region agent log
    debug_log("app.py:71", "DocumentProcessor IMPORTADO", {}, "A")
    # #endregion
    # NÃ£o usar print() aqui - sys.stdout pode estar fechado com Streamlit
except Exception as e:
    # #region agent log
    debug_log("app.py:75", "ERRO ao importar processor", {"error": str(e), "error_type": type(e).__name__}, "A,E")
    # #endregion
    # NÃ£o usar print() aqui - sys.stdout pode estar fechado com Streamlit
    # Verificar se DocumentProcessor foi importado mesmo assim
    try:
        from processor import DocumentProcessor
        # DocumentProcessor disponÃ­vel apesar do erro - continuar
    except:
        # Se nÃ£o conseguir importar, nÃ£o fazer raise para nÃ£o bloquear o app
        # #region agent log
        debug_log("app.py:84", "DocumentProcessor NÃƒO DISPONÃVEL", {"error": str(e)}, "A,E")
        # #endregion
        pass

from config import settings
from vectorstore import VectorStore
from analyzer import DocumentAnalyzer
from storage import ResponseStorage
from file_manager import FileManager

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lise de Processos JurÃ­dicos",
    page_icon="âš–ï¸",
    layout="wide"
)

# TÃ­tulo
st.title("âš–ï¸ AnÃ¡lise Inteligente de Processos JurÃ­dicos")
st.markdown("**Powered by GPT-4.1 + pypdf + Supabase**")
st.markdown("---")

# Inicializar componentes
@st.cache_resource
def init_components():
    try:
        # #region agent log
        debug_log("app.py:112", "INICIANDO init_components", {}, "C")
        # #endregion
        
        # #region agent log
        debug_log("app.py:114", "Criando VectorStore", {}, "C")
        # #endregion
        vectorstore = VectorStore()
        
        # #region agent log
        debug_log("app.py:116", "Criando DocumentProcessor", {}, "C")
        # #endregion
        processor = DocumentProcessor()
        
        # #region agent log
        debug_log("app.py:118", "Criando DocumentAnalyzer", {}, "C")
        # #endregion
        analyzer = DocumentAnalyzer(vectorstore=vectorstore)
        
        # #region agent log
        debug_log("app.py:120", "Criando ResponseStorage", {}, "C")
        # #endregion
        storage = ResponseStorage()
        
        # #region agent log
        debug_log("app.py:122", "Criando FileManager", {}, "C")
        # #endregion
        file_manager = FileManager()
        
        # #region agent log
        debug_log("app.py:124", "COMPONENTES INICIALIZADOS", {"processor": str(type(processor)), "vectorstore": str(type(vectorstore))}, "C")
        # #endregion
        
        return {
            "processor": processor,
            "vectorstore": vectorstore,
            "analyzer": analyzer,
            "storage": storage,
            "file_manager": file_manager
        }
    except Exception as e:
        # #region agent log
        debug_log("app.py:131", "ERRO ao inicializar componentes", {"error": str(e), "error_type": type(e).__name__}, "C,E")
        # #endregion
        import traceback
        error_details = traceback.format_exc()
        debug_log("app.py:134", "TRACEBACK init_components", {"traceback": error_details[:2000]}, "C,E")
        st.error(f"âŒ Erro ao inicializar componentes: {str(e)}")
        st.warning("âš ï¸ Verifique se o arquivo .env estÃ¡ configurado corretamente")
        st.code(error_details[:1000])
        return None

# #region agent log
debug_log("app.py:140", "CHAMANDO init_components", {}, "C")
# #endregion
components = init_components()

# #region agent log
debug_log("app.py:143", "init_components RETORNOU", {"components_is_none": components is None}, "C")
# #endregion

if components is None:
    # #region agent log
    debug_log("app.py:145", "COMPONENTES NONE - PARANDO", {}, "C,E")
    # #endregion
    st.error("âš ï¸ NÃ£o foi possÃ­vel inicializar a aplicaÃ§Ã£o. Verifique o arquivo .env")
    st.stop()

# Inicializar estado da sessÃ£o
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'stop_requested' not in st.session_state:
    st.session_state.stop_requested = False
if 'logs' not in st.session_state:
    st.session_state.logs = []

# Lock para thread-safety nos logs e status
log_lock = Lock()
progress_lock = Lock()

# Sidebar - ConfiguraÃ§Ãµes
st.sidebar.header("âš™ï¸ ConfiguraÃ§Ãµes")

folder_path = st.sidebar.text_input(
    "ðŸ“ Caminho da Pasta com PDFs",
    placeholder=r"E:\Documentos\PDFs",
    help="Digite o caminho completo da pasta contendo os arquivos PDF"
)

batch_size = st.sidebar.number_input(
    "ðŸ“¦ Quantidade de documentos por lote",
    min_value=1,
    max_value=100,
    value=5,
    help="Quantos documentos processar por vez"
)

# Processamento sequencial - multithread removido

# BotÃµes de controle
st.sidebar.markdown("---")
st.sidebar.markdown("### ðŸŽ® Controles")
col1, col2 = st.sidebar.columns(2)
with col1:
    start_button = st.button("â–¶ï¸ Iniciar", type="primary", disabled=st.session_state.processing or not folder_path, use_container_width=True)
with col2:
    stop_button = st.button("â¹ï¸ Parar", disabled=not st.session_state.processing, use_container_width=True)

if stop_button:
    st.session_state.stop_requested = True
    st.sidebar.warning("âš ï¸ Parada solicitada...")

# EstatÃ­sticas na sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("### ðŸ“Š EstatÃ­sticas")
try:
    all_files = components["file_manager"].get_all()
    if all_files:
        status_counts = {}
        for file_data in all_files:
            status = file_data.get("status", "PENDENTE")
            status_counts[status] = status_counts.get(status, 0) + 1
        
        st.sidebar.metric("âœ… ConcluÃ­dos", status_counts.get("CONCLUIDO", 0))
        st.sidebar.metric("â³ Processando", status_counts.get("PROCESSANDO", 0))
        st.sidebar.metric("â¸ï¸ Pendentes", status_counts.get("PENDENTE", 0))
        erro_count = status_counts.get("ERRO", 0)
        st.sidebar.metric("âŒ Erros", erro_count)
        st.sidebar.metric("âœ“ JÃ¡ Processados", status_counts.get("JA_PROCESSADO", 0))
        
        # BotÃ£o para limpar status de ERRO
        if erro_count > 0:
            st.sidebar.markdown("---")
            if st.sidebar.button("ðŸ§¹ Limpar Status de ERRO", help="Reseta todos os arquivos com status ERRO para PENDENTE"):
                try:
                    reset_count = components["file_manager"].reset_errors()
                    st.sidebar.success(f"âœ… {reset_count} arquivo(s) resetado(s) para PENDENTE")
                    st.rerun()
                except Exception as e:
                    st.sidebar.error(f"âŒ Erro ao limpar status: {str(e)}")
except:
    pass

# FunÃ§Ã£o para adicionar log (thread-safe)
def add_log(message, level="INFO"):
    """Adiciona mensagem ao log de forma thread-safe"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    with log_lock:
        st.session_state.logs.append(f"[{timestamp}] {level}: {message}")

# FunÃ§Ãµes helper para atualizaÃ§Ãµes seguras de UI (evitam erros de WebSocket fechado)
def safe_update_logs(log_display, logs, max_lines=50):
    """Atualiza logs de forma segura, ignorando erros de WebSocket fechado"""
    try:
        if log_display is not None and logs:
            log_text = "\n".join(logs[-max_lines:])
            if log_text.strip():  # SÃ³ atualizar se houver logs
                try:
                    log_display.code(log_text, language="text")
                except:
                    # Fallback: tentar usar text ao invÃ©s de code
                    try:
                        log_display.text(log_text)
                    except:
                        # Ãšltimo fallback: usar markdown
                        log_display.markdown(f"```\n{log_text}\n```")
    except (Exception, RuntimeError, AttributeError, TypeError):
        # Ignorar erros de WebSocket fechado e outros erros assÃ­ncronos
        pass
    except:
        # Capturar qualquer outro erro silenciosamente
        pass

def safe_update_progress(progress_bar, value):
    """Atualiza barra de progresso de forma segura"""
    try:
        if progress_bar is not None:
            progress_bar.progress(min(max(value, 0.0), 1.0))
    except (Exception, RuntimeError, AttributeError, TypeError):
        # Ignorar erros de WebSocket fechado e outros erros assÃ­ncronos
        pass
    except:
        # Capturar qualquer outro erro silenciosamente
        pass

def safe_streamlit_call(func, *args, **kwargs):
    """Chama funÃ§Ãµes do Streamlit de forma segura"""
    try:
        return func(*args, **kwargs)
    except (Exception, RuntimeError, AttributeError, TypeError):
        # Ignorar erros de WebSocket fechado e outros erros assÃ­ncronos
        pass
    except:
        # Capturar qualquer outro erro silenciosamente
        pass

def safe_rerun():
    """Chama st.rerun() de forma segura"""
    try:
        st.rerun()
    except (Exception, RuntimeError, AttributeError, TypeError):
        # Ignorar erros de WebSocket fechado ao fazer rerun
        pass
    except:
        # Capturar qualquer outro erro silenciosamente
        pass

# Criar tabs
tab1, tab2 = st.tabs(["ðŸ“¤ Processamento", "ðŸ“š Documentos Analisados"])

# Aba 1: Processamento
with tab1:
    # OpÃ§Ã£o: Upload de arquivo Ãºnico ou processar pasta
    st.markdown("### ðŸ“¤ Escolha o mÃ©todo de processamento")
    opcao_processamento = st.radio(
        "Selecione:",
        ["ðŸ“ Processar pasta", "ðŸ“„ Fazer upload de arquivo Ãºnico"],
        horizontal=True
    )
    
    st.markdown("---")
    
    # Upload de arquivo Ãºnico
    if opcao_processamento == "ðŸ“„ Fazer upload de arquivo Ãºnico":
        uploaded_file = st.file_uploader(
            "Escolha um arquivo PDF",
            type=["pdf"],
            help="FaÃ§a upload de um Ãºnico arquivo PDF para processar"
        )
        
        if uploaded_file is not None:
            # #region agent log
            debug_log("app.py:249", "UPLOADED FILE DETECTED", {"filename": uploaded_file.name, "size_bytes": len(uploaded_file.getbuffer())}, "A")
            # #endregion
            
            # Salvar arquivo temporariamente
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getbuffer())
                tmp_path = tmp_file.name
            
            filename = uploaded_file.name
            file_size_mb = len(uploaded_file.getbuffer()) / (1024 * 1024)
            
            # Salvar tmp_path no session_state para persistir entre reruns
            st.session_state['uploaded_tmp_path'] = tmp_path
            st.session_state['uploaded_filename'] = filename
            st.session_state['uploaded_file_size_mb'] = file_size_mb
            
            # #region agent log
            debug_log("app.py:257", "TEMP FILE CREATED", {"tmp_path": tmp_path, "filename": filename, "tmp_path_exists": os.path.exists(tmp_path)}, "A,F")
            # #endregion
            
            st.success(f"âœ… Arquivo carregado: **{filename}** ({file_size_mb:.2f} MB)")
        
        # Usar dados do session_state se disponÃ­vel (apÃ³s rerun)
        if 'uploaded_tmp_path' in st.session_state:
            tmp_path = st.session_state['uploaded_tmp_path']
            filename = st.session_state['uploaded_filename']
            file_size_mb = st.session_state['uploaded_file_size_mb']
            
            # #region agent log
            debug_log("app.py:270", "USING SESSION STATE", {"tmp_path": tmp_path, "filename": filename, "tmp_path_exists": os.path.exists(tmp_path) if tmp_path else False}, "A")
            # #endregion
            
            # Verificar se jÃ¡ foi processado
            try:
                existing = components["file_manager"].get_by_filename(filename)
                # #region agent log
                debug_log("app.py:263", "EXISTING FILE CHECK", {"filename": filename, "existing": existing is not None, "status": existing.get("status") if existing else None}, "A")
                # #endregion
                if existing and existing.get("status") == "CONCLUIDO":
                    # #region agent log
                    debug_log("app.py:265", "FILE ALREADY CONCLUIDO", {"filename": filename}, "A")
                    # #endregion
                    st.info(f"â„¹ï¸ **{filename}** jÃ¡ foi processado anteriormente.")
                    if st.button(f"ðŸ”„ Reprocessar {filename}", type="primary"):
                        # #region agent log
                        debug_log("app.py:267", "REPROCESS BUTTON CLICKED", {"filename": filename}, "A")
                        # #endregion
                        # Resetar status para processar novamente
                        components["file_manager"].update_status(filename, "PENDENTE", existing_data=existing)
                        safe_rerun()
                elif existing and existing.get("status") == "PROCESSANDO":
                    # #region agent log
                    debug_log("app.py:271", "FILE ALREADY PROCESSANDO", {"filename": filename}, "A")
                    # #endregion
                    st.warning(f"âš ï¸ **{filename}** estÃ¡ sendo processado. Aguarde a conclusÃ£o.")
                else:
                    # #region agent log
                    debug_log("app.py:294", "FILE READY TO PROCESS", {"filename": filename, "processing_state": st.session_state.processing, "existing": existing is not None}, "A")
                    # #endregion
                    
                    # Registrar no banco se necessÃ¡rio
                    try:
                        if not existing:
                            # #region agent log
                            debug_log("app.py:299", "REGISTERING NEW FILE", {"filename": filename}, "A")
                            # #endregion
                            components["file_manager"].register_file(filename, file_size_mb, tmp_path)
                    except Exception as reg_error:
                        # #region agent log
                        debug_log("app.py:299", "REGISTER FILE ERROR", {"filename": filename, "error": str(reg_error)}, "A")
                        # #endregion
                        pass
                    
                    # #region agent log
                    debug_log("app.py:305", "BEFORE BUTTON RENDER", {"filename": filename, "processing_state": st.session_state.processing, "existing_status": existing.get("status") if existing else None, "tmp_path": tmp_path, "tmp_path_exists": os.path.exists(tmp_path) if tmp_path else False}, "A")
                    # #endregion
                    
                    # VERIFICAR SE tmp_path EXISTE
                    if not tmp_path:
                        st.error(f"âŒ Erro: tmp_path nÃ£o definido para {filename}")
                    elif not os.path.exists(tmp_path):
                        st.error(f"âŒ Erro: Arquivo temporÃ¡rio nÃ£o encontrado: {tmp_path}")
                        st.warning("ðŸ’¡ Tente fazer upload do arquivo novamente.")
                    else:
                        # Arquivo existe, mostrar informaÃ§Ã£o
                        file_size = os.path.getsize(tmp_path) / (1024 * 1024)
                        st.caption(f"ðŸ“ Arquivo pronto: {file_size:.2f} MB")
                    
                    # Verificar se pode processar
                    can_process = not st.session_state.processing
                    if existing and existing.get("status") == "PROCESSANDO":
                        can_process = False
                    if not tmp_path or not os.path.exists(tmp_path):
                        can_process = False  # NÃ£o pode processar se arquivo nÃ£o existe
                    
                    # BotÃ£o para processar - sÃ³ desabilitado quando estiver processando
                    button_label = f"â–¶ï¸ Processar {filename}"
                    if not can_process:
                        if not tmp_path or not os.path.exists(tmp_path):
                            button_label = f"âŒ Arquivo nÃ£o encontrado"
                        else:
                            button_label = f"â¸ï¸ Processando..." if st.session_state.processing else f"â³ Aguarde..."
                    
                    button_clicked = st.button(
                        button_label, 
                        type="primary", 
                        disabled=not can_process,
                        key=f"process_btn_{filename}"
                    )
                    
                    # #region agent log
                    debug_log("app.py:318", "AFTER BUTTON RENDER", {"filename": filename, "button_clicked": button_clicked, "processing_state": st.session_state.processing, "can_process": can_process}, "A")
                    # #endregion
                    
                    if button_clicked and can_process:
                        # #region agent log
                        debug_log("app.py:283", "BUTTON CLICKED - INSIDE IF", {"filename": filename, "tmp_path": tmp_path, "tmp_path_exists": os.path.exists(tmp_path) if tmp_path else False}, "A")
                        # #endregion
                        
                        # Marcar como processando e salvar flag para iniciar processamento
                        st.session_state.processing = True
                        st.session_state.stop_requested = False
                        st.session_state.logs = []
                        st.session_state['should_start_processing'] = filename
                        
                        # ForÃ§ar rerun imediato para desabilitar o botÃ£o
                        st.rerun()
                    
                    # Verificar se deve iniciar o processamento (apÃ³s rerun quando botÃ£o foi clicado)
                    should_start = st.session_state.get('should_start_processing') == filename
                    add_log(f"ðŸ”µ DEBUG: should_start={should_start}, processing={st.session_state.processing}, filename={filename}", "DEBUG")
                    
                    if should_start and st.session_state.processing:
                        # Limpar flag para nÃ£o reiniciar em loops
                        st.session_state['should_start_processing'] = None
                        
                        # VERIFICAR SE ARQUIVO EXISTE ANTES DE PROCESSAR
                        if not tmp_path or not os.path.exists(tmp_path):
                            error_msg = f"âŒ ERRO CRÃTICO: Arquivo temporÃ¡rio nÃ£o encontrado! tmp_path={tmp_path}, exists={os.path.exists(tmp_path) if tmp_path else False}"
                            add_log(error_msg, "ERROR")
                            st.error(error_msg)
                            st.session_state.processing = False
                            if 'uploaded_tmp_path' in st.session_state:
                                del st.session_state['uploaded_tmp_path']
                            if 'uploaded_filename' in st.session_state:
                                del st.session_state['uploaded_filename']
                            if 'uploaded_file_size_mb' in st.session_state:
                                del st.session_state['uploaded_file_size_mb']
                            safe_rerun()
                        else:
                            add_log(f"âœ… Arquivo encontrado: {tmp_path} ({os.path.getsize(tmp_path)} bytes)", "DEBUG")
                        
                        # Logs em tempo real
                        st.markdown("### ðŸ“‹ Logs do Processamento")
                        log_display = st.empty()
                        progress_bar = st.progress(0)
                        
                        add_log(f"Iniciando processamento de {filename}")
                        add_log(f"ðŸ“ Arquivo: {tmp_path}")
                        add_log(f"ðŸ“Š Tamanho: {os.path.getsize(tmp_path) / (1024*1024):.2f} MB")
                        
                        chunks_count = [0]
                        
                        try:
                            # Atualizar status para PROCESSANDO
                            components["file_manager"].update_status(filename, "PROCESSANDO")
                            add_log(f"Iniciando: {filename}")
                            
                            safe_update_logs(log_display, st.session_state.logs)
                            
                            def save_chunks_batch(chunks_batch):
                                # Log IMEDIATO quando callback Ã© chamado
                                add_log(f"{filename}: ðŸ”µ CALLBACK RECEBIDO - {len(chunks_batch)} chunks", "DEBUG")
                                
                                chunks_count[0] += len(chunks_batch)
                                add_log(f"{filename}: {len(chunks_batch)} chunks recebidos no callback")
                                add_log(f"{filename}: Total acumulado: {chunks_count[0]} chunks processados")
                                try:
                                    # Log ANTES de chamar store_chunks
                                    add_log(f"{filename}: ðŸ”µ ANTES DE CHAMAR store_chunks com {len(chunks_batch)} chunks...")
                                    
                                    # CHAMADA CRÃTICA - adicionar log aqui
                                    components["vectorstore"].store_chunks(chunks_batch)
                                    
                                    add_log(f"{filename}: âœ… {len(chunks_batch)} chunks salvos no banco com sucesso")
                                except Exception as e:
                                    import traceback
                                    error_details = traceback.format_exc()
                                    add_log(f"{filename}: âŒ ERRO ao salvar chunks - {str(e)}", "ERROR")
                                    add_log(f"{filename}: Traceback: {error_details[:1000]}", "ERROR")
                                    raise
                            
                            add_log(f"{filename}: Extraindo texto...")
                            safe_update_progress(progress_bar, 0.1)
                            
                            # #region agent log
                            debug_log("app.py:312", "BEFORE process_incremental call", {"tmp_path": tmp_path, "filename": filename, "tmp_path_exists": os.path.exists(tmp_path) if tmp_path else False}, "A,F")
                            # #endregion
                            
                            try:
                                add_log(f"{filename}: ðŸ”µ CHAMANDO process_incremental...")
                                doc = components["processor"].process_incremental(
                                    tmp_path,
                                    filename=filename,
                                    chunk_callback=save_chunks_batch,
                                    batch_size=5  # Reduzido para salvar chunks imediatamente apÃ³s extraÃ§Ã£o
                                )
                                add_log(f"{filename}: âœ… process_incremental concluÃ­do!")
                                # #region agent log
                                debug_log("app.py:319", "AFTER process_incremental SUCCESS", {"doc_keys": list(doc.keys()) if doc else None, "total_pages": doc.get('metadata', {}).get('total_pages') if doc else None}, "A")
                                # #endregion
                            except Exception as e:
                                # #region agent log
                                debug_log("app.py:319", "process_incremental ERROR", {"error": str(e), "error_type": type(e).__name__}, "A,E")
                                # #endregion
                                raise
                            
                            total_pages = doc.get('metadata', {}).get('total_pages', 0)
                            add_log(f"{filename}: {total_pages} pÃ¡ginas, {chunks_count[0]} chunks processados")
                            safe_update_progress(progress_bar, 0.9)
                            
                            # Verificar se chunks foram salvos no banco
                            if chunks_count[0] > 0:
                                document_id = doc.get("document_id")
                                if document_id:
                                    try:
                                        has_chunks = components["vectorstore"].has_chunks(document_id=document_id)
                                        add_log(f"{filename}: âœ… VerificaÃ§Ã£o final - Chunks no banco: {has_chunks}")
                                        if has_chunks:
                                            # Contar quantos chunks existem
                                            try:
                                                from supabase import create_client
                                                from config import settings
                                                supabase = create_client(settings.SUPABASE_URL, settings.SUPABASE_KEY)
                                                result = supabase.table(settings.TABLE_EMBEDDINGS).select("id", count="exact").eq("document_id", document_id).execute()
                                                count = result.count if hasattr(result, 'count') else len(result.data) if result.data else 0
                                                add_log(f"{filename}: âœ… Total de {count} chunks salvos na tabela documento_chunks")
                                            except Exception as count_error:
                                                add_log(f"{filename}: Aviso - Erro ao contar chunks: {str(count_error)}", "WARNING")
                                    except Exception as check_error:
                                        add_log(f"{filename}: Aviso - Erro ao verificar chunks: {str(check_error)}", "WARNING")
                                
                                # Atualizar status para CONCLUIDO
                                components["file_manager"].update_status(
                                    filename,
                                    "CONCLUIDO",
                                    document_id=doc["document_id"],
                                    total_chunks=chunks_count[0],
                                    total_pages=total_pages
                                )
                                add_log(f"{filename}: Status CONCLUIDO atualizado")
                                
                                safe_update_progress(progress_bar, 1.0)
                                add_log(f"âœ… {filename} concluÃ­do! ({chunks_count[0]} chunks extraÃ­dos e embeddings gerados)")
                                
                                safe_streamlit_call(st.success, f"âœ… **{filename}** concluÃ­do! ({chunks_count[0]} chunks extraÃ­dos e embeddings gerados)")
                                safe_streamlit_call(st.balloons)
                                
                                # ANÃLISE AUTOMÃTICA DESABILITADA TEMPORARIAMENTE PARA ACELERAR PROCESSAMENTO
                                # Para habilitar novamente, descomente o cÃ³digo abaixo:
                                """
                                add_log(f"{filename}: Iniciando anÃ¡lise RAG...")
                                try:
                                    analise_result, resposta_bruta = components["analyzer"].analyze_full_document_rag(
                                        doc["document_id"],
                                        filename,
                                        return_raw_response=True
                                    )
                                    components["storage"].save_analysis(**analise_result)
                                    add_log(f"{filename}: AnÃ¡lise salva com sucesso")
                                except Exception as e:
                                    add_log(f"{filename}: ERRO na anÃ¡lise - {str(e)}", "ERROR")
                                """
                            else:
                                add_log(f"{filename}: âš ï¸ Nenhum chunk criado", "WARNING")
                                components["file_manager"].update_status(
                                    filename,
                                    "ERRO",
                                    error_message="Nenhum chunk foi criado"
                                )
                                safe_streamlit_call(st.error, f"âŒ **{filename}**: Nenhum chunk foi criado")
                            
                        except Exception as e:
                            error_msg = str(e)
                            add_log(f"{filename}: ERRO no processamento - {error_msg}", "ERROR")
                            components["file_manager"].update_status(
                                filename,
                                "ERRO",
                                error_message=f"Erro processamento: {error_msg[:200]}"
                            )
                            safe_streamlit_call(st.error, f"âŒ **{filename}**: {error_msg}")
                        finally:
                            st.session_state.processing = False
                            safe_update_logs(log_display, st.session_state.logs)
                            
                            # Limpar arquivo temporÃ¡rio e session_state
                            try:
                                if tmp_path and os.path.exists(tmp_path):
                                    os.unlink(tmp_path)
                            except:
                                pass
                            
                            # Limpar dados do session_state
                            if 'uploaded_tmp_path' in st.session_state:
                                del st.session_state['uploaded_tmp_path']
                            if 'uploaded_filename' in st.session_state:
                                del st.session_state['uploaded_filename']
                            if 'uploaded_file_size_mb' in st.session_state:
                                del st.session_state['uploaded_file_size_mb']
                            
                            safe_rerun()
            except Exception as e:
                st.error(f"âŒ Erro ao verificar status: {str(e)}")
    
    # Processar pasta (cÃ³digo existente)
    elif opcao_processamento == "ðŸ“ Processar pasta":
        # Ãrea principal
        if folder_path and os.path.exists(folder_path):
            # Buscar PDFs na pasta
            pdf_files = glob.glob(os.path.join(folder_path, "*.pdf"))
            
            if pdf_files:
                # Ordenar por tamanho (menor para maior)
                pdf_files_with_size = [(f, os.path.getsize(f)) for f in pdf_files]
                pdf_files_with_size.sort(key=lambda x: x[1])  # Ordenar por tamanho
                pdf_files = [f[0] for f in pdf_files_with_size]  # Pegar apenas os caminhos
                
                st.success(f"âœ… {len(pdf_files)} arquivo(s) PDF encontrado(s) na pasta (ordenados do menor para o maior)")
                
                # Registrar arquivos no banco se necessÃ¡rio
                for pdf_file in pdf_files:
                    filename = os.path.basename(pdf_file)
                    file_size_mb = os.path.getsize(pdf_file) / (1024 * 1024)
                    
                    try:
                        # Verificar se jÃ¡ existe no banco
                        existing = components["file_manager"].get_by_filename(filename)
                        if not existing:
                            # Registrar novo arquivo
                            try:
                                components["file_manager"].register_file(filename, file_size_mb, pdf_file)
                            except Exception as e:
                                pass  # Ignorar se jÃ¡ existe ou erro de conexÃ£o
                        elif existing and existing.get("status") not in ["CONCLUIDO", "JA_PROCESSADO"]:
                            # Atualizar tamanho se necessÃ¡rio
                            if existing.get("file_size_mb") != file_size_mb:
                                try:
                                    components["file_manager"].update_status(
                                        filename, 
                                        existing.get("status"),
                                        existing_data=existing  # Passar existing para evitar nova query
                                    )
                                except Exception:
                                    pass  # Ignorar erro de conexÃ£o
                    except Exception:
                        pass  # Continuar mesmo se houver erro
            
            # Buscar status de todos os arquivos do banco
            all_file_statuses = {}
            try:
                db_files = components["file_manager"].get_all()
                for db_file in db_files:
                    all_file_statuses[db_file["filename"]] = db_file
            except:
                pass
            
            # Mostrar tabela de documentos
            st.markdown("### ðŸ“Š Status dos Documentos")
            
            # Criar DataFrame para exibiÃ§Ã£o
            docs_data = []
            for pdf_file in pdf_files:
                filename = os.path.basename(pdf_file)
                size_mb = os.path.getsize(pdf_file) / (1024 * 1024)
                
                db_file = all_file_statuses.get(filename, {})
                status = db_file.get("status", "PENDENTE")
                
                # Formatar status para exibiÃ§Ã£o
                error_msg = db_file.get('error_message') or 'Erro desconhecido'
                if isinstance(error_msg, str) and len(error_msg) > 30:
                    error_msg = error_msg[:30] + "..."
                
                status_display = {
                    "PENDENTE": "â¸ï¸ Pendente",
                    "PROCESSANDO": "â³ Processando",
                    "CONCLUIDO": "âœ… ConcluÃ­do",
                    "ERRO": f"âŒ Erro: {error_msg}",
                    "JA_PROCESSADO": "âœ… JÃ¡ processado"
                }.get(status, status)
                
                chunks = db_file.get("total_chunks", 0)
                pages = db_file.get("total_pages", 0)
                
                docs_data.append({
                    "Arquivo": filename,
                    "Tamanho (MB)": f"{size_mb:.2f}",
                    "Status": status_display,
                    "Chunks": str(chunks) if chunks else "-",
                    "PÃ¡ginas": str(pages) if pages else "-"
                })
            
            # Exibir tabela Ãºnica com todos os documentos
            if docs_data:
                df = pd.DataFrame(docs_data)
                st.dataframe(df, width='stretch', height=400)
                
                # Processar documentos
                if start_button:
                    st.session_state.processing = True
                    st.session_state.stop_requested = False
                    st.session_state.logs = []
                    
                    add_log(f"Iniciando processamento em lote de atÃ© {batch_size} documentos")
                    
                    # Resetar documentos travados em PROCESSANDO de execuÃ§Ãµes anteriores
                    try:
                        stuck_files = components["file_manager"].get_all("PROCESSANDO")
                        for stuck in stuck_files:
                            components["file_manager"].update_status(
                                stuck["filename"],
                                "PENDENTE",
                                existing_data=stuck
                            )
                        if stuck_files:
                            add_log(f"Resetados {len(stuck_files)} arquivo(s) travados em PROCESSANDO")
                    except:
                        pass
                    
                    # REBUSCAR status atualizado do banco apÃ³s o reset
                    all_file_statuses = {}
                    try:
                        db_files = components["file_manager"].get_all()
                        for db_file in db_files:
                            all_file_statuses[db_file["filename"]] = db_file
                        add_log(f"Status atualizado do banco: {len(all_file_statuses)} arquivo(s) carregados")
                    except Exception as e:
                        add_log(f"Erro ao rebuscar status: {str(e)}", "WARNING")
                    
                    # Logs em tempo real
                    st.markdown("---")
                    st.markdown("### ðŸ“‹ Logs do Processamento")
                    log_display = st.empty()
                    progress_bar = st.progress(0)
                    
                    # Atualizar logs inicialmente
                    safe_update_logs(log_display, st.session_state.logs)
                    
                    # Filtrar documentos pendentes (ordenados por tamanho) usando status ATUALIZADO
                    docs_to_process = []
                    for pdf_file in pdf_files:  # JÃ¡ ordenados por tamanho
                        filename = os.path.basename(pdf_file)
                        db_file = all_file_statuses.get(filename, {})  # Usar status ATUALIZADO
                        status = db_file.get("status", "PENDENTE")
                        
                        if status in ["PENDENTE", "ERRO"]:
                            docs_to_process.append(pdf_file)
                            add_log(f"Adicionado Ã  fila: {filename} (status: {status})", "DEBUG")
                            if len(docs_to_process) >= batch_size:
                                break
                    
                    add_log(f"Documentos pendentes selecionados: {len(docs_to_process)} (ordenados do menor para o maior)")
                    total_docs = len(docs_to_process)
                    
                    # Atualizar logs apÃ³s seleÃ§Ã£o
                    safe_update_logs(log_display, st.session_state.logs)
                    
                    if total_docs == 0:
                        st.info("â„¹ï¸ Nenhum documento pendente para processar!")
                        st.session_state.processing = False
                    else:
                        # Processar documentos sequencialmente
                        add_log(f"Iniciando processamento sequencial de {total_docs} documentos")
                        safe_update_logs(log_display, st.session_state.logs)
                        
                        # Criar funÃ§Ã£o para processar um documento
                        def process_single_document(pdf_file, idx, total_docs):
                            """Processa um Ãºnico documento"""
                            filename = os.path.basename(pdf_file)
                            
                            try:
                                # Atualizar status para PROCESSANDO
                                try:
                                    components["file_manager"].update_status(filename, "PROCESSANDO")
                                except:
                                    pass
                                
                                add_log(f"[{idx+1}/{total_docs}] Iniciando: {filename}")
                                
                                # Verificar se jÃ¡ tem chunks/embeddings salvos
                                existing_file_data = components["file_manager"].get_by_filename(filename)
                                doc = None
                                chunks_count = [0]
                                
                                # Verificar se jÃ¡ tem chunks no banco
                                if existing_file_data and existing_file_data.get("document_id") and existing_file_data.get("total_chunks", 0) > 0:
                                    document_id_existing = existing_file_data["document_id"]
                                    
                                    # Verificar se chunks realmente existem no banco
                                    if components["vectorstore"].has_chunks(document_id=document_id_existing):
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: Chunks jÃ¡ existem no banco, reutilizando...")
                                        chunks_count[0] = existing_file_data.get("total_chunks", 0)
                                        total_pages = existing_file_data.get("total_pages", 0)
                                        
                                        # Criar objeto doc simulado com o document_id existente
                                        doc = {
                                            "document_id": document_id_existing,
                                            "filename": filename,
                                            "metadata": {
                                                "total_pages": total_pages
                                            }
                                        }
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: Reutilizando {chunks_count[0]} chunks existentes")
                                    else:
                                        # Document_id salvo mas chunks nÃ£o existem mais, reprocessar
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: Document ID encontrado mas chunks nÃ£o existem, reprocessando...")
                                        doc = None
                                
                                # Se nÃ£o tem chunks, processar PDF
                                if doc is None:
                                    chunks_count = [0]
                                    
                                    def save_chunks_batch(chunks_batch, document_id, filename_cb):
                                        # Log IMEDIATO quando callback Ã© chamado
                                        add_log(f"[{idx+1}/{total_docs}] {filename_cb}: ðŸ”µ CALLBACK RECEBIDO - {len(chunks_batch)} chunks", "DEBUG")
                                        
                                        chunks_count[0] += len(chunks_batch)
                                        add_log(f"[{idx+1}/{total_docs}] {filename_cb}: {len(chunks_batch)} chunks recebidos no callback")
                                        add_log(f"[{idx+1}/{total_docs}] {filename_cb}: Total acumulado: {chunks_count[0]} chunks processados")
                                        try:
                                            # Log ANTES de chamar store_chunks
                                            add_log(f"[{idx+1}/{total_docs}] {filename_cb}: ðŸ”µ ANTES DE CHAMAR store_chunks com {len(chunks_batch)} chunks...")
                                            
                                            # CHAMADA CRÃTICA - adicionar log aqui
                                            components["vectorstore"].store_chunks(chunks_batch)
                                            
                                            add_log(f"[{idx+1}/{total_docs}] {filename_cb}: âœ… {len(chunks_batch)} chunks salvos no banco com sucesso")
                                        except Exception as e:
                                            import traceback
                                            error_details = traceback.format_exc()
                                            add_log(f"[{idx+1}/{total_docs}] {filename_cb}: âŒ ERRO ao salvar chunks - {str(e)}", "ERROR")
                                            add_log(f"[{idx+1}/{total_docs}] {filename_cb}: Traceback: {error_details[:1000]}", "ERROR")
                                            raise
                                    
                                    add_log(f"[{idx+1}/{total_docs}] {filename}: Extraindo texto...")
                                    
                                    doc = components["processor"].process_incremental(
                                        pdf_file,
                                        filename=filename,
                                        chunk_callback=save_chunks_batch,
                                        batch_size=5  # Reduzido para salvar chunks imediatamente apÃ³s extraÃ§Ã£o
                                    )
                                    
                                    total_pages = doc.get('metadata', {}).get('total_pages', 0)
                                    add_log(f"[{idx+1}/{total_docs}] {filename}: {total_pages} pÃ¡ginas, {chunks_count[0]} chunks")
                                
                                # Verificar se chunks foram salvos e atualizar status
                                if chunks_count[0] > 0:
                                    document_id = doc.get("document_id")
                                    if document_id:
                                        try:
                                            has_chunks = components["vectorstore"].has_chunks(document_id=document_id)
                                            add_log(f"[{idx+1}/{total_docs}] {filename}: âœ… VerificaÃ§Ã£o final - Chunks no banco: {has_chunks}")
                                            if has_chunks:
                                                # Contar quantos chunks existem
                                                try:
                                                    from supabase import create_client
                                                    from config import settings
                                                    supabase = create_client(settings.SUPABASE_URL, settings.SUPABASE_KEY)
                                                    result = supabase.table(settings.TABLE_EMBEDDINGS).select("id", count="exact").eq("document_id", document_id).execute()
                                                    count = result.count if hasattr(result, 'count') else len(result.data) if result.data else 0
                                                    add_log(f"[{idx+1}/{total_docs}] {filename}: âœ… Total de {count} chunks salvos na tabela documento_chunks")
                                                except:
                                                    pass
                                        except Exception as check_error:
                                            add_log(f"[{idx+1}/{total_docs}] {filename}: Aviso - Erro ao verificar chunks: {str(check_error)}", "WARNING")
                                    
                                    # Atualizar status para CONCLUIDO
                                    try:
                                        status_result = components["file_manager"].update_status(
                                            filename,
                                            "CONCLUIDO",
                                            document_id=doc["document_id"],
                                            total_chunks=chunks_count[0],
                                            total_pages=total_pages
                                        )
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: Status CONCLUIDO atualizado")
                                        add_log(f"[{idx+1}/{total_docs}] âœ… {filename} concluÃ­do! ({chunks_count[0]} chunks extraÃ­dos e embeddings gerados)")
                                    except Exception as status_error:
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: ERRO status - {str(status_error)}", "ERROR")
                                    
                                    # ANÃLISE AUTOMÃTICA DESABILITADA TEMPORARIAMENTE PARA ACELERAR PROCESSAMENTO
                                    # Para habilitar novamente, descomente o cÃ³digo abaixo:
                                    """
                                    add_log(f"[{idx+1}/{total_docs}] {filename}: Iniciando anÃ¡lise RAG...")
                                    try:
                                        analise_result, resposta_bruta = components["analyzer"].analyze_full_document_rag(
                                            doc["document_id"],
                                            filename,
                                            return_raw_response=True
                                        )
                                        components["storage"].save_analysis(**analise_result)
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: AnÃ¡lise salva com sucesso")
                                    except Exception as e:
                                        add_log(f"[{idx+1}/{total_docs}] {filename}: ERRO na anÃ¡lise - {str(e)}", "ERROR")
                                    """
                                    
                                    return {"success": True, "filename": filename, "idx": idx}
                                else:
                                    add_log(f"[{idx+1}/{total_docs}] {filename}: âš ï¸ Nenhum chunk encontrado", "WARNING")
                                    return {"success": False, "filename": filename, "idx": idx, "error": "Nenhum chunk"}
                            
                            except Exception as proc_error:
                                add_log(f"[{idx+1}/{total_docs}] {filename}: ERRO no processamento - {str(proc_error)}", "ERROR")
                                try:
                                    components["file_manager"].update_status(
                                        filename,
                                        "ERRO",
                                        error_message=f"Erro processamento: {str(proc_error)[:200]}"
                                    )
                                except:
                                    pass
                                return {"success": False, "filename": filename, "idx": idx, "error": str(proc_error)}
                        
                        # Processar documentos sequencialmente
                        completed_count = 0
                        add_log(f"ðŸ”„ Processando {total_docs} documentos sequencialmente...")
                        safe_update_logs(log_display, st.session_state.logs)
                        
                        for idx, pdf_file in enumerate(docs_to_process):
                            if st.session_state.stop_requested:
                                add_log("â¹ï¸ Processamento interrompido pelo usuÃ¡rio")
                                break
                            
                            try:
                                add_log(f"ðŸ“„ Processando [{idx+1}/{total_docs}]: {os.path.basename(pdf_file)}")
                                safe_update_logs(log_display, st.session_state.logs)
                                
                                result = process_single_document(pdf_file, idx, total_docs)
                                completed_count += 1
                                
                                # Log do resultado
                                if result and result.get("success"):
                                    add_log(f"âœ… [{idx+1}/{total_docs}] {result.get('filename')} concluÃ­do")
                                else:
                                    error_msg = result.get('error', 'Erro desconhecido') if result else 'Nenhum resultado retornado'
                                    add_log(f"âŒ [{idx+1}/{total_docs}] {result.get('filename', os.path.basename(pdf_file))} falhou: {error_msg}", "ERROR")
                                
                                # Atualizar progresso apÃ³s cada documento
                                try:
                                    safe_update_progress(progress_bar, completed_count / total_docs)
                                    safe_update_logs(log_display, st.session_state.logs)
                                except:
                                    pass
                                
                            except Exception as e:
                                import traceback
                                error_details = traceback.format_exc()
                                filename = os.path.basename(pdf_file)
                                
                                add_log(f"âŒ ERRO CRÃTICO ao processar [{idx+1}/{total_docs}] {filename}: {str(e)}", "ERROR")
                                add_log(f"Tipo do erro: {type(e).__name__}", "ERROR")
                                add_log(f"Traceback: {error_details[:1500]}", "ERROR")
                                
                                # Tentar atualizar status do arquivo para ERRO
                                try:
                                    components["file_manager"].update_status(
                                        filename,
                                        "ERRO",
                                        error_message=f"Erro processamento: {str(e)[:200]}"
                                    )
                                except:
                                    pass
                                
                                completed_count += 1  # Contar mesmo com erro
                                
                                # Atualizar progresso
                                try:
                                    safe_update_progress(progress_bar, completed_count / total_docs)
                                    safe_update_logs(log_display, st.session_state.logs)
                                except:
                                    pass
                        
                        add_log(f"âœ… Processamento concluÃ­do: {completed_count}/{total_docs} documentos processados")
                        
                        # Finalizar processamento
                        st.session_state.processing = False
                        safe_update_progress(progress_bar, 1.0)
                        safe_update_logs(log_display, st.session_state.logs)
                    
                    # Finalizar processamento
                    st.session_state.processing = False
                    safe_update_progress(progress_bar, 1.0)
                    add_log("âœ… Processamento finalizado!")
                    safe_update_logs(log_display, st.session_state.logs)
                    
                    if not st.session_state.stop_requested:
                        safe_streamlit_call(st.balloons)
                        safe_streamlit_call(st.success, "ðŸŽ‰ Processamento em lote concluÃ­do!")
                    
                    st.rerun()
        else:
            st.warning("âš ï¸ Nenhum arquivo PDF encontrado na pasta especificada")
    elif folder_path:
        st.error(f"âŒ Caminho nÃ£o encontrado: {folder_path}")
    else:
        st.info("ðŸ‘† Digite o caminho da pasta com os PDFs no painel lateral")

    # Exibir logs se houver
    if st.session_state.logs:
        st.markdown("---")
        st.markdown("### ðŸ“‹ Logs Recentes")
        log_text = "\n".join(st.session_state.logs[-100:])
        if log_text.strip():
            st.code(log_text, language="text", line_numbers=False)
        else:
            st.info("â„¹ï¸ Logs vazios")
    elif st.session_state.processing:
        st.info("â³ Processamento em andamento... Os logs aparecerÃ£o aqui em breve.")

# Aba 2: Visualizar Documentos Analisados
with tab2:
    st.markdown("### ðŸ“š Documentos Analisados")
    st.markdown("Visualize e consulte as anÃ¡lises jurÃ­dicas jÃ¡ processadas.")
    
    try:
        # Buscar todas as anÃ¡lises
        all_analyses = components["storage"].get_all()
        
        if not all_analyses:
            st.info("ðŸ“­ Nenhum documento analisado ainda. Processe alguns documentos na aba de Processamento.")
        else:
            # Filtros
            col1, col2, col3 = st.columns(3)
            
            with col1:
                filter_processo = st.text_input(
                    "ðŸ” Filtrar por NÃºmero do Processo",
                    placeholder="0000000-00.0000.0.00.0000",
                    help="Digite o nÃºmero do processo para buscar"
                )
            
            with col2:
                filter_arquivo = st.text_input(
                    "ðŸ“„ Filtrar por Nome do Arquivo",
                    placeholder="Nome do arquivo",
                    help="Digite parte do nome do arquivo"
                )
            
            with col3:
                filter_juiz = st.text_input(
                    "âš–ï¸ Filtrar por Juiz",
                    placeholder="Nome do juiz",
                    help="Digite o nome do juiz"
                )
            
            # Aplicar filtros
            filtered_analyses = all_analyses
            
            if filter_processo:
                filtered_analyses = [a for a in filtered_analyses if filter_processo.lower() in a.get("numero_processo", "").lower()]
            
            if filter_arquivo:
                filtered_analyses = [a for a in filtered_analyses if filter_arquivo.lower() in a.get("arquivo_original", "").lower()]
            
            if filter_juiz:
                filtered_analyses = [a for a in filtered_analyses if filter_juiz.lower() in (a.get("juiz") or "").lower()]
            
            st.markdown(f"**Total encontrado:** {len(filtered_analyses)} documento(s)")
            st.markdown("---")
            
            # Lista de documentos
            if filtered_analyses:
                for idx, analysis in enumerate(filtered_analyses):
                    with st.expander(
                        f"ðŸ“„ {analysis.get('arquivo_original', 'Sem nome')} - {analysis.get('numero_processo', 'Sem processo')}",
                        expanded=False
                    ):
                        col_info1, col_info2 = st.columns(2)
                        
                        with col_info1:
                            st.markdown("**ðŸ“‹ InformaÃ§Ãµes do Processo**")
                            st.markdown(f"**NÃºmero do Processo:** {analysis.get('numero_processo', 'N/A')}")
                            st.markdown(f"**Arquivo:** {analysis.get('arquivo_original', 'N/A')}")
                            st.markdown(f"**Juiz:** {analysis.get('juiz', 'N/A')}")
                            st.markdown(f"**Vara:** {analysis.get('vara', 'N/A')}")
                            st.markdown(f"**Tribunal:** {analysis.get('tribunal', 'N/A')}")
                        
                        with col_info2:
                            st.markdown("**ðŸ“… InformaÃ§Ãµes da DecisÃ£o**")
                            st.markdown(f"**Data da DecisÃ£o:** {analysis.get('data_decisao', 'N/A')}")
                            st.markdown(f"**Tipo de DecisÃ£o:** {analysis.get('tipo_decisao', 'N/A')}")
                            st.markdown(f"**Analisado por:** {analysis.get('analisado_por', 'N/A')}")
                            created_at = analysis.get('created_at')
                            if created_at:
                                try:
                                    from datetime import datetime
                                    dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                                    st.markdown(f"**Data de AnÃ¡lise:** {dt.strftime('%d/%m/%Y %H:%M')}")
                                except:
                                    st.markdown(f"**Data de AnÃ¡lise:** {created_at}")
                        
                        # DecisÃ£o do Juiz
                        decisao_resposta = analysis.get('decisao_resposta')
                        if decisao_resposta:
                            st.markdown("---")
                            st.markdown("### ðŸŽ¯ DecisÃ£o do Juiz sobre DesconsideraÃ§Ã£o")
                            st.markdown(f"**Resposta:** {decisao_resposta}")
                            
                            decisao_justificativa = analysis.get('decisao_justificativa')
                            if decisao_justificativa:
                                st.markdown(f"**Justificativa:** {decisao_justificativa}")
                            
                            decisao_referencia = analysis.get('decisao_referencia')
                            if decisao_referencia:
                                st.markdown(f"**ReferÃªncia:** {decisao_referencia}")
                        
                        # Listar todas as perguntas e respostas
                        st.markdown("---")
                        st.markdown("### ðŸ“ Respostas Ã s Perguntas")
                        
                        # Carregar perguntas do prompt
                        def carregar_perguntas():
                            perguntas_map = {}
                            try:
                                with open("prompt_analise.txt", "r", encoding="utf-8") as f:
                                    content = f.read()
                                    import re
                                    # Buscar padrÃ£o [1.1], [1.2], etc. seguido da pergunta
                                    pattern = r'\[\*?(\d+)\.(\d+)\*?\]\s+(.+?)(?=\n\n\*\*p\d+_|$)'
                                    matches = re.finditer(pattern, content, re.DOTALL)
                                    for match in matches:
                                        bloco = match.group(1)
                                        num = match.group(2)
                                        pergunta_texto = match.group(3).strip()
                                        # Limpar marcaÃ§Ã£o markdown e quebras de linha
                                        pergunta_texto = re.sub(r'\*\*', '', pergunta_texto)
                                        pergunta_texto = re.sub(r'\n+', ' ', pergunta_texto).strip()
                                        key = f"p{bloco}_{num}"
                                        perguntas_map[key] = pergunta_texto
                            except Exception as e:
                                pass
                            return perguntas_map
                        
                        perguntas_map = carregar_perguntas()
                        
                        # Agrupar campos por pergunta (p1_1_resposta, p1_1_justificativa, p1_1_referencia)
                        perguntas_dict = {}
                        for key, value in analysis.items():
                            if key.startswith('p') and ('_resposta' in key or '_justificativa' in key or '_referencia' in key):
                                # Extrair ID da pergunta (ex: p1_1 de p1_1_resposta)
                                pergunta_id = key.rsplit('_', 1)[0]
                                tipo = key.split('_')[-1]
                                
                                if pergunta_id not in perguntas_dict:
                                    perguntas_dict[pergunta_id] = {}
                                perguntas_dict[pergunta_id][tipo] = value
                        
                        # Ordenar perguntas
                        sorted_perguntas = sorted(perguntas_dict.items(), key=lambda x: (
                            int(x[0].split('_')[0][1:]),  # NÃºmero do bloco (p1, p2, etc)
                            int(x[0].split('_')[1])        # NÃºmero da pergunta (1, 2, etc)
                        ))
                        
                        # Exibir cada pergunta
                        for pergunta_id, campos in sorted_perguntas:
                            # Buscar texto da pergunta ou usar ID como fallback
                            pergunta_texto = perguntas_map.get(pergunta_id, pergunta_id.upper().replace('_', '.'))
                            # Limitar tamanho do tÃ­tulo se muito longo
                            titulo = pergunta_texto if len(pergunta_texto) <= 100 else pergunta_texto[:97] + "..."
                            
                            with st.expander(f"**{titulo}**", expanded=False):
                                if 'resposta' in campos:
                                    st.markdown(f"**Resposta:** {campos['resposta']}")
                                if 'justificativa' in campos:
                                    st.markdown(f"**Justificativa:** {campos['justificativa']}")
                                if 'referencia' in campos:
                                    st.markdown(f"**ReferÃªncia:** {campos['referencia']}")
                        
                        st.markdown("---")
            
            else:
                st.warning("ðŸ” Nenhum documento encontrado com os filtros aplicados.")
                
    except Exception as e:
        st.error(f"âŒ Erro ao buscar anÃ¡lises: {str(e)}")
        st.exception(e)
